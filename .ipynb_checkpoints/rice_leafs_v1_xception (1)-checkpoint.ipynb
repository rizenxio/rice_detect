{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWe_jjyzYur_",
        "outputId": "566010df-82f4-4062-fa68-1a82dd91bff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZGnEAyGfxwsx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Activation,Dropout,Conv2D,MaxPool2D,Flatten,Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import os\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from IPython.display import display,HTML\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcIBPHOXujS",
        "outputId": "f4d0462b-4b28-4813-fd9f-8b1b9aa2b360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo7qSp7LYvUB"
      },
      "outputs": [],
      "source": [
        "# import rarfile\n",
        "# local_file = '/content/drive/MyDrive/rice.rar'\n",
        "# with rarfile.RarFile(local_file, 'r') as rar_ref:\n",
        "#     rar_ref.extractall('data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qOt378ouyVXX"
      },
      "outputs": [],
      "source": [
        "# extract data zip\n",
        "local_file = '/content/drive/MyDrive/rice.zip'\n",
        "zipreff = zipfile.ZipFile(local_file,'r')\n",
        "zipreff.extractall('data/')\n",
        "zipreff.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "JVLD-6bP16VD",
        "outputId": "328207cf-136a-450e-9639-a2d768f87c12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "labels\n",
              "withouthawar    1000\n",
              "other           1000\n",
              "hawar           1000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>withouthawar</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hawar</th>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "sdir = '/content/data/rice/'\n",
        "\n",
        "filepaths = []\n",
        "labels = []\n",
        "classlist = os.listdir(sdir)\n",
        "for kelas in classlist:\n",
        "  classpath = os.path.join(sdir,kelas)\n",
        "  if os.path.isdir(classpath):\n",
        "    flist = os.listdir(classpath)\n",
        "    for f in flist:\n",
        "      fpath = os.path.join(classpath,f)\n",
        "      filepaths.append(fpath)\n",
        "      labels.append(kelas)\n",
        "Fseries = pd.Series(filepaths,name='filepaths')\n",
        "Lseries = pd.Series(labels,name='labels')\n",
        "df = pd.concat([Fseries,Lseries], axis =1)\n",
        "df.head()\n",
        "df['labels'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image():\n",
        "  test_dict = test_gen.class_indices\n",
        "  classes = list(test_dict.keys())\n",
        "  images,labels = next(training_datagen)\n",
        "  plt.figure(figsize=(20,20))\n",
        "  length = len(labels)\n",
        "  if length<25:\n",
        "    r=length\n",
        "  else:\n",
        "    r=25\n",
        "  for i in range(r):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    image = images[i]\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])\n",
        "    class_name = classes[index]\n",
        "    plt.title(class_name,color='blue',fontsize=16)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7wxhpZ68hDyI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o1JqeAlGhPSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hb07WXa4xg8"
      },
      "source": [
        "#memsihkan data training,data test, dan validasi test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2paag0e4J1J",
        "outputId": "c92a8870-965e-42bc-d6cb-ae7d9313e192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df_length:  2700  test_df_length:  150  valid_df length:  150\n"
          ]
        }
      ],
      "source": [
        "train_split = .9\n",
        "test_split = .05\n",
        "dummy_split = test_split/(1-train_split)\n",
        "train_df, dummy_df = train_test_split(df,train_size=train_split,shuffle=True,random_state=123)\n",
        "test_df, valid_df = train_test_split(dummy_df,train_size=dummy_split,shuffle=True,random_state=123)\n",
        "print('train_df_length: ',len(train_df),' test_df_length: ',len(test_df),' valid_df length: ',len(valid_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTUpy2-77DNO"
      },
      "source": [
        "### membuat training , tes dan validasi generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRZL4CRi6u6G",
        "outputId": "2d04f89e-42f0-4bb8-afbe-23eb7e45243f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test batch size:  75  test steps:  2\n"
          ]
        }
      ],
      "source": [
        "height = 256\n",
        "width = 256\n",
        "channel =3\n",
        "batch_size = 64\n",
        "img_shape = (height,width,channel)\n",
        "img_size = (height,width)\n",
        "length = len(test_df)\n",
        "test_batch_size = sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]\n",
        "test_steps = int(length/test_batch_size)\n",
        "print('test batch size: ',test_batch_size,' test steps: ',test_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXdPtDWJBU1T",
        "outputId": "c2be5bc8-2a52-40b8-8114-6c5f4b63597f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2700 validated image filenames belonging to 3 classes.\n",
            "Found 150 validated image filenames belonging to 3 classes.\n",
            "Found 150 validated image filenames belonging to 3 classes.\n",
            "['hawar', 'other', 'withouthawar']\n"
          ]
        }
      ],
      "source": [
        "#perubahan dengan image data generator untuk mengurangi val loss\n",
        "training_datagen=ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "training_generator=training_datagen.flow_from_dataframe(\n",
        "    train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size\n",
        ")\n",
        "validgen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_gen=validgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "testgen=ImageDataGenerator(rescale=1./255)\n",
        "test_gen=testgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
        "\n",
        "classes=list(training_generator.class_indices.keys())\n",
        "print(classes)\n",
        "class_count=len(classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Xpkm8_vTJgRk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "o_Bmf8OZLOVS",
        "outputId": "4a07a1ed-e675-463b-bd8c-6800a7c3e079"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "show_image() takes 0 positional arguments but 1 was given",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1e9ccc504bb9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: show_image() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "show_image(training_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3ElK6Zc5LP9n"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "base_model=tf.keras.applications.Xception(include_top=False,\n",
        "                                          weights=\"imagenet\",\n",
        "                                          input_tensor=Input(shape=(256,256,3)\n",
        "                                          ))\n",
        "\n",
        "# base_model.summary()\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "07iY__d4PKEQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tra4CR_JPLq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2558e9-9ff3-407f-bb93-9ceb4c6855bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model with <Functional name=xception, built=True>\n"
          ]
        }
      ],
      "source": [
        "model_name='bahrur'\n",
        "print(\"Building model with\", base_model)\n",
        "model = tf.keras.Sequential([\n",
        "            # Note the input shape is the desired size of the image 128x128 with 3 bytes color\n",
        "            # This is the first convolution\n",
        "            tf.keras.layers.Input(shape=(256, 256, 3)),\n",
        "            base_model,\n",
        "            tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu', strides=1),\n",
        "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "            tf.keras.layers.Dropout(rate=0.5),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WSSXddLiPOdj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "0671f08e-b176-4371-a34a-7d5982ce1324"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ xception (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m20,861,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │         \u001b[38;5;34m589,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │           \u001b[38;5;34m1,539\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ xception (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">589,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,452,875\u001b[0m (81.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,452,875</span> (81.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m591,395\u001b[0m (2.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">591,395</span> (2.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,861,480\u001b[0m (79.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,861,480</span> (79.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        accuracy = logs.get('accuracy')\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        if accuracy is not None and val_accuracy is not None:\n",
        "            if accuracy > 0.99 and val_accuracy > 0.99:\n",
        "                print(\"\\nDesired accuracy and validation_accuracy reached. Stopping training.\")\n",
        "                self.model.stop_training = True"
      ],
      "metadata": {
        "id": "_BSDIeHRuVO5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF66NPpiPTKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "239bdbc8-9eb4-4633-f53f-b4d1733fe150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - accuracy: 0.6195 - loss: 0.8981 - val_accuracy: 0.7467 - val_loss: 0.4986\n",
            "Epoch 2/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - accuracy: 0.7522 - loss: 0.5019 - val_accuracy: 0.7933 - val_loss: 0.4397\n",
            "Epoch 3/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.7907 - loss: 0.4251 - val_accuracy: 0.8200 - val_loss: 0.3293\n",
            "Epoch 4/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.8082 - loss: 0.3866 - val_accuracy: 0.7933 - val_loss: 0.4937\n",
            "Epoch 5/40\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.7932 - loss: 0.4157 - val_accuracy: 0.8133 - val_loss: 0.3779\n",
            "Epoch 6/40\n",
            "\u001b[1m34/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m28s\u001b[0m 3s/step - accuracy: 0.8053 - loss: 0.3683"
          ]
        }
      ],
      "source": [
        "epochs =40\n",
        "my_callback = MyCallback()\n",
        "\n",
        "history=model.fit(x=training_generator, epochs=epochs, validation_data=valid_gen,callbacks=[my_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en0xo8DAPXkv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
        "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple\n",
        "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
        "    rf,gf,bf=fore_tupple\n",
        "    rb,gb,bb=back_tupple\n",
        "    msg='{0}' + txt_msg\n",
        "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m'\n",
        "    print(msg .format(mat), flush=True)\n",
        "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
        "    return\n",
        "\n",
        "\"\"\"## **definefunction to plot the training data**\"\"\"\n",
        "\n",
        "def tr_plot(tr_data, start_epoch):\n",
        "    #Plot the training and validation data\n",
        "    tacc=tr_data.history['accuracy']\n",
        "    tloss=tr_data.history['loss']\n",
        "    vacc=tr_data.history['val_accuracy']\n",
        "    vloss=tr_data.history['val_loss']\n",
        "    Epoch_count=len(tacc)+ start_epoch\n",
        "    Epochs=[]\n",
        "    for i in range (start_epoch ,Epoch_count):\n",
        "        Epochs.append(i+1)\n",
        "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
        "    val_lowest=vloss[index_loss]\n",
        "    index_acc=np.argmax(vacc)\n",
        "    acc_highest=vacc[index_acc]\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
        "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
        "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
        "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
        "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
        "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].set_xlabel('Epochs')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
        "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
        "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epochs')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "    plt.tight_layout\n",
        "    #plt.style.use('fivethirtyeight')\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"#### **define function to generate the confusion matrix and classification report**\"\"\"\n",
        "\n",
        "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
        "    class_dict=test_gen.class_indices\n",
        "    labels= test_gen.labels\n",
        "    file_names= test_gen.filenames\n",
        "    error_list=[]\n",
        "    true_class=[]\n",
        "    pred_class=[]\n",
        "    prob_list=[]\n",
        "    new_dict={}\n",
        "    error_indices=[]\n",
        "    y_pred=[]\n",
        "    for key,value in class_dict.items():\n",
        "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
        "    # store new_dict as a text fine in the save_dir\n",
        "    classes=list(new_dict.values())     # list of string of class names\n",
        "    dict_as_text=str(new_dict)\n",
        "    dict_name= subject + '-' +str(len(classes)) +'.txt'\n",
        "    dict_path=os.path.join(save_dir,dict_name)\n",
        "    with open(dict_path, 'w') as x_file:\n",
        "        x_file.write(dict_as_text)\n",
        "    errors=0\n",
        "    for i, p in enumerate(preds):\n",
        "        pred_index=np.argmax(p)\n",
        "        true_index=labels[i]  # labels are integer values\n",
        "        if pred_index != true_index: # a misclassification has occurred\n",
        "            error_list.append(file_names[i])\n",
        "            true_class.append(new_dict[true_index])\n",
        "            pred_class.append(new_dict[pred_index])\n",
        "            prob_list.append(p[pred_index])\n",
        "            error_indices.append(true_index)\n",
        "            errors=errors + 1\n",
        "        y_pred.append(pred_index)\n",
        "    if print_code !=0:\n",
        "        if errors>0:\n",
        "            if print_code>errors:\n",
        "                r=errors\n",
        "            else:\n",
        "                r=print_code\n",
        "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
        "            print_in_color(msg, (0,255,0),(55,65,80))\n",
        "            for i in range(r):\n",
        "                split1=os.path.split(error_list[i])\n",
        "                split2=os.path.split(split1[0])\n",
        "                fname=split2[1] + '/' + split1[1]\n",
        "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n",
        "                print_in_color(msg, (255,255,255), (55,65,60))\n",
        "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])\n",
        "        else:\n",
        "            msg='With accuracy of 100 % there are no errors to print'\n",
        "            print_in_color(msg, (0,255,0),(55,65,80))\n",
        "    if errors>0:\n",
        "        plot_bar=[]\n",
        "        plot_class=[]\n",
        "        for  key, value in new_dict.items():\n",
        "            count=error_indices.count(key)\n",
        "            if count!=0:\n",
        "                plot_bar.append(count) # list containg how many times a class c had an error\n",
        "                plot_class.append(value)   # stores the class\n",
        "        fig=plt.figure()\n",
        "        fig.set_figheight(len(plot_class)/3)\n",
        "        fig.set_figwidth(10)\n",
        "        plt.style.use('fivethirtyeight')\n",
        "        for i in range(0, len(plot_class)):\n",
        "            c=plot_class[i]\n",
        "            x=plot_bar[i]\n",
        "            plt.barh(c, x, )\n",
        "            plt.title( ' Errors by Class on Test Set')\n",
        "    y_true= np.array(labels)\n",
        "    y_pred=np.array(y_pred)\n",
        "    if len(classes)<= 30:\n",
        "        # create a confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred )\n",
        "        length=len(classes)\n",
        "        if length<8:\n",
        "            fig_width=8\n",
        "            fig_height=8\n",
        "        else:\n",
        "            fig_width= int(length * .5)\n",
        "            fig_height= int(length * .5)\n",
        "        plt.figure(figsize=(fig_width, fig_height))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n",
        "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
        "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
        "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "\n",
        "\"\"\"### evaluate model on the test set then save the model\"\"\"\n",
        "\n",
        "tr_plot(history,0)\n",
        "save_dir=r'./'\n",
        "subject='pest'\n",
        "acc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n",
        "msg=f'accuracy on the test set is {acc:5.2f} %'\n",
        "print_in_color(msg, (0,255,0),(55,65,80))\n",
        "save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
        "save_loc=os.path.join(save_dir, save_id)\n",
        "model.save(save_loc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtFJCuREisHl"
      },
      "outputs": [],
      "source": [
        "print_code=0\n",
        "preds=model.predict(test_gen)\n",
        "print_info( test_gen, preds, print_code, save_dir, subject )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "073pemDDCIvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gedx9AUGcrMH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}